{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b51f9b-d2de-4608-ae2c-e7ec567a78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put this near the top of your file\n",
    "def set_all_seeds(seed: int):\n",
    "    import os, random, numpy as np\n",
    "    from transformers.trainer_utils import set_seed as hf_set_seed\n",
    "    hf_set_seed(seed)                     # covers python, numpy, torch (and sets cudnn flags)\n",
    "    try:\n",
    "        from accelerate.utils import set_seed as accel_set_seed\n",
    "        accel_set_seed(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # extra determinism (optional; may error on some ops)\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(False)  # True if you want strict determinism\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543daa9-5db8-4298-a629-99daf5eec237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, time\n",
    "\n",
    "class _JsonlWriter:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "        self.f = open(path, \"a\", encoding=\"utf-8\")\n",
    "    def write(self, record: dict):\n",
    "        self.f.write(json.dumps(record, ensure_ascii=False) + \"\\n\"); self.f.flush()\n",
    "    def close(self):\n",
    "        try: self.f.close()\n",
    "        except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e553f9-9c6d-4b83-bf8e-c1ead3c7d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from trl import DPOTrainer\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _fmt_logs(d):\n",
    "    parts = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, float):\n",
    "            parts.append(f\"{k}={v:.6f}\")\n",
    "        else:\n",
    "            parts.append(f\"{k}={v}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "\n",
    "# --------- utils: concat + continuation-only mask ----------\n",
    "def _concat_ids(a, b): return torch.cat([a, b], dim=1)\n",
    "\n",
    "def _cont_mask(prompt_mask, resp_mask):\n",
    "    # 0 over prompt, 1 over response; then shift by 1 for next-token prediction\n",
    "    zeros = torch.zeros_like(prompt_mask)\n",
    "    return torch.cat([zeros, resp_mask], dim=1)[:, 1:]  # [B, T-1]\n",
    "\n",
    "# --------- core: response-only log-prob SUM per sample ----------\n",
    "def _response_logprob_sum_from_ids(model, full_ids, full_attn, cont_mask):\n",
    "    \"\"\"\n",
    "    Sum of log p(y_t | x, y_<t>) over RESPONSE tokens only (masked by cont_mask).\n",
    "    cont_mask: [B, T-1] with 1 over response positions and 0 elsewhere.\n",
    "    \"\"\"\n",
    "    m = getattr(model, \"module\", model)\n",
    "    emb = m.get_input_embeddings()\n",
    "    e_dev = emb.weight.device\n",
    "\n",
    "    # Start on the embedding device\n",
    "    full_ids  = full_ids.to(e_dev, non_blocking=True)\n",
    "    full_attn = full_attn.to(e_dev, dtype=torch.long, non_blocking=True)\n",
    "\n",
    "    # Build embeddings explicitly on the correct device\n",
    "    inputs_embeds = emb(full_ids)  # [B, T, H] on e_dev\n",
    "\n",
    "    # Forward: keep everything starting on e_dev so the dispatcher can shard correctly\n",
    "    outputs = m(inputs_embeds=inputs_embeds, attention_mask=full_attn, use_cache=False)\n",
    "    logits  = outputs.logits                          # [B, T, V] (may live on another GPU)\n",
    "    logp    = F.log_softmax(logits[:, :-1, :], dim=-1)\n",
    "\n",
    "    # Move gather inputs to the logits' device before use\n",
    "    dev     = logits.device\n",
    "    targets = full_ids[:, 1:].to(dev, non_blocking=True)       # [B, T-1]\n",
    "    msk     = cont_mask.to(dev, dtype=logp.dtype, non_blocking=True)\n",
    "\n",
    "    tok_lp  = torch.gather(logp, 2, targets.unsqueeze(-1)).squeeze(-1)  # [B, T-1]\n",
    "    return (tok_lp * msk).sum(dim=1)                                    # [B]\n",
    "\n",
    "\n",
    "\n",
    "class AuxDPOTrainer(DPOTrainer):\n",
    "    \"\"\"\n",
    "    Batchwise AuxDPO:\n",
    "      - Uses response-only log-probs given prompt (same masking logic as your snippet).\n",
    "      - DPO margin augmented by (delta_chosen - delta_rejected).\n",
    "      - Null penalty: ||A_batch^T delta_batch||^2, where rows of A are ref-model grads of log p(y|x).\n",
    "      - Anti-collapse: small incentive for ||delta_batch|| to not collapse to 0 (tanh-bounded).\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 *args,\n",
    "                 lambda_null: float = 1.0,     # weight on ||A^T δ||^2\n",
    "                 lambda_amp: float = 0.01,     # weight on -||δ||^2 (anti-collapse)\n",
    "                 delta_cap: float = 1.0,       # bound |δ_i| ≤ delta_cap via tanh\n",
    "                 aux_lr: float = 5e-3,         # LR for δ\n",
    "                 seed: int = 42,\n",
    "                 **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        set_all_seeds(int(seed))\n",
    "        self.experiment_seed = int(seed)\n",
    "\n",
    "        # 1) Frozen reference (if not provided)\n",
    "        if self.ref_model is None:\n",
    "            self.ref_model = copy.deepcopy(self.model)\n",
    "            for p in self.ref_model.parameters(): p.requires_grad = False\n",
    "            self.ref_model.eval()\n",
    "        self._ref_on_device = False\n",
    "\n",
    "        # 2) Global delta (size 2N); live on the main device so it’s trainable\n",
    "        assert self.train_dataset is not None, \"train_dataset required to size δ\"\n",
    "        self.N = len(self.train_dataset)\n",
    "        # --- REGISTER δ ON THE MODEL (so DDP/ZeRO/Accelerate sees it) ---\n",
    "        dev = self.accelerator.device\n",
    "        self.model.register_parameter(\n",
    "            \"aux_delta_raw\",\n",
    "            nn.Parameter(torch.zeros(2 * self.N, dtype=torch.float32, device=dev))\n",
    "        )\n",
    "        self.delta_raw = self.model.aux_delta_raw\n",
    "        # small noise so grad at step 0 isn’t exactly zero\n",
    "        torch.nn.init.normal_(self.delta_raw, mean=0.0, std=1e-3)\n",
    "        self.delta_cap = float(delta_cap)\n",
    "\n",
    "        # 3) Choose ref params to differentiate (match trainable names; fallback to 'lora_')\n",
    "        self._grad_params = []\n",
    "        ref_named = dict(self.ref_model.named_parameters())\n",
    "        for n, p in self.model.named_parameters():\n",
    "            if p.requires_grad and (n in ref_named):\n",
    "                self._grad_params.append(ref_named[n])\n",
    "        if not self._grad_params:\n",
    "            self._grad_params = [p for n, p in self.ref_model.named_parameters() if \"lora_\" in n]\n",
    "\n",
    "        self.lambda_null = float(lambda_null)\n",
    "        self.lambda_amp  = float(lambda_amp)\n",
    "        self.delta_cap   = float(delta_cap)\n",
    "        self.aux_lr      = float(aux_lr)\n",
    "\n",
    "    def _ensure_ref_on_device(self):\n",
    "        if self._ref_on_device:\n",
    "            return\n",
    "        dtype = next(self.model.parameters()).dtype\n",
    "        # If ref is already sharded, leave placement alone\n",
    "        if getattr(self.ref_model, \"hf_device_map\", None):\n",
    "            self.ref_model.eval()\n",
    "            for p in self.ref_model.parameters():\n",
    "                p.requires_grad = False\n",
    "        else:\n",
    "            dev = self.accelerator.device\n",
    "            self.ref_model.to(dev, dtype=dtype)\n",
    "            self.ref_model.eval()\n",
    "            for p in self.ref_model.parameters():\n",
    "                p.requires_grad = False\n",
    "        self._ref_on_device = True\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _grad_norm(model) -> float:\n",
    "        sq = []\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                g = p.grad.detach().float()\n",
    "                sq.append((g.norm(2) ** 2))\n",
    "        return float(torch.sqrt(torch.stack(sq).sum()).item()) if sq else 0.0\n",
    "\n",
    "    # ensure δ gets its own param group\n",
    "    @staticmethod\n",
    "    def _optimizer_has_param(optimizer, param) -> bool:\n",
    "        for g in optimizer.param_groups:\n",
    "            for p in g.get(\"params\", []):\n",
    "                if p is param:            # identity, not equality\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def create_optimizer(self):\n",
    "        super().create_optimizer()\n",
    "        assert hasattr(self, \"delta_raw\")\n",
    "        if not any(p is self.delta_raw\n",
    "                   for g in self.optimizer.param_groups\n",
    "                   for p in g.get(\"params\", [])):\n",
    "            self.optimizer.add_param_group({\n",
    "                \"params\": [self.delta_raw],\n",
    "                \"lr\": self.aux_lr,\n",
    "                \"weight_decay\": 0.0\n",
    "            })\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _input_device_for(model):\n",
    "        m = getattr(model, \"module\", model)\n",
    "        try:\n",
    "            return m.get_input_embeddings().weight.device\n",
    "        except Exception:\n",
    "            return next(m.parameters()).device  # last resort\n",
    "    \n",
    "    \n",
    "    # --- response-only scores for chosen/rejected under a model ---\n",
    "    def _pair_scores_ids(self, model, batch, need_grad: bool):\n",
    "        dev = self._input_device_for(model)\n",
    "        p_ids = batch[\"prompt_input_ids\"].to(dev, non_blocking=True)\n",
    "        p_msk = batch[\"prompt_attention_mask\"].to(dev, non_blocking=True)\n",
    "        c_ids = batch[\"chosen_input_ids\"].to(dev, non_blocking=True)\n",
    "        c_msk = batch[\"chosen_attention_mask\"].to(dev, non_blocking=True)\n",
    "        r_ids = batch[\"rejected_input_ids\"].to(dev, non_blocking=True)\n",
    "        r_msk = batch[\"rejected_attention_mask\"].to(dev, non_blocking=True)\n",
    "    \n",
    "        ch_full, ch_mask = _concat_ids(p_ids, c_ids), _concat_ids(p_msk, c_msk)\n",
    "        rj_full, rj_mask = _concat_ids(p_ids, r_ids), _concat_ids(p_msk, r_msk)\n",
    "        ch_cont = _cont_mask(p_msk, c_msk)   # [B, T_ch-1], 1 over response tokens\n",
    "        rj_cont = _cont_mask(p_msk, r_msk)   # [B, T_rj-1]\n",
    "    \n",
    "        ctx = torch.enable_grad() if need_grad else torch.no_grad()\n",
    "        with ctx:\n",
    "            ch = _response_logprob_sum_from_ids(model, ch_full, ch_mask, ch_cont)\n",
    "            rj = _response_logprob_sum_from_ids(model, rj_full, rj_mask, rj_cont)\n",
    "        return ch, rj\n",
    "\n",
    "\n",
    "\n",
    "    # --- compute A_batch^T δ_batch via one weighted backward on ref-model ---\n",
    "    def _AT_delta(self, batch, delta_chosen, delta_rejected):\n",
    "        \"\"\"\n",
    "        Return ||A_batch^T delta_batch||^2 with grads ONLY w.r.t. delta.\n",
    "        We:\n",
    "          1) compute per-sample ∇_θ log p_ref with create_graph=False,\n",
    "          2) immediately .detach() those grads,\n",
    "          3) accumulate Σ_i δ_i * ∇_θ log p_i into a param-shaped vector,\n",
    "          4) L2^2 of that vector.\n",
    "        \"\"\"\n",
    "        if not self._grad_params:\n",
    "            return torch.tensor(0.0, device=self.accelerator.device)\n",
    "    \n",
    "        # Temporarily ensure we can take grads w.r.t. ref params for autograd.grad\n",
    "        toggled = []\n",
    "        for p in self._grad_params:\n",
    "            if not p.requires_grad:\n",
    "                p.requires_grad_(True); toggled.append(p)\n",
    "    \n",
    "        # Need per-sample scalars with graph on (to take grads), but we won't keep\n",
    "        # a higher-order graph: create_graph=False and we detach the results.\n",
    "        ch_ref, rj_ref = self._pair_scores_ids(self.ref_model, batch, need_grad=True)  # [B], [B]\n",
    "    \n",
    "        # Accumulator (same shapes as params)\n",
    "        # Accumulator (match dtype + device of each param)\n",
    "        acc = [torch.zeros_like(p, device=p.device, dtype=p.dtype) for p in self._grad_params]\n",
    "        \n",
    "        B = ch_ref.shape[0]\n",
    "        for j in range(B):\n",
    "            g_ch = torch.autograd.grad(\n",
    "                ch_ref[j], self._grad_params,\n",
    "                retain_graph=True, create_graph=False, allow_unused=True\n",
    "            )\n",
    "            g_rj = torch.autograd.grad(\n",
    "                rj_ref[j], self._grad_params,\n",
    "                retain_graph=True, create_graph=False, allow_unused=True\n",
    "            )\n",
    "        \n",
    "            for k, p_k in enumerate(self._grad_params):\n",
    "                dev_k = p_k.device\n",
    "        \n",
    "                if g_ch[k] is not None:\n",
    "                    djc = delta_chosen[j].to(dev_k)  # keep δ as a tensor (preserve grads)\n",
    "                    acc[k] = acc[k] + djc * g_ch[k].detach()\n",
    "        \n",
    "                if g_rj[k] is not None:\n",
    "                    djr = delta_rejected[j].to(dev_k)  # keep δ as a tensor (preserve grads)\n",
    "                    acc[k] = acc[k] + djr * g_rj[k].detach()\n",
    "        \n",
    "        # ||A^T δ||^2 (use a stable dtype if params are bf16/fp16)\n",
    "        # Initialize pen on a single device (e.g., accelerator device)\n",
    "        pen = torch.zeros((), device=self.accelerator.device, dtype=torch.float32)\n",
    "        \n",
    "        for a in acc:\n",
    "            # local sum on the tensor's device (keeps graph w.r.t. deltas)\n",
    "            term = a.float().pow(2).sum()\n",
    "            # move the scalar to pen's device before accumulating\n",
    "            pen = pen + term.to(pen.device)\n",
    "\n",
    "    \n",
    "        # Turn ref params back off\n",
    "        for p in toggled:\n",
    "            p.requires_grad_(False)\n",
    "    \n",
    "        return pen\n",
    "\n",
    "\n",
    "    # --- main loss ---\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        beta = getattr(self, \"beta\", 0.1)\n",
    "        dev  = self.accelerator.device\n",
    "\n",
    "        # current model margin WITH grad\n",
    "        ch, rj = self._pair_scores_ids(model, inputs, need_grad=True)\n",
    "        ch, rj = ch.to(dev), rj.to(dev)\n",
    "        \n",
    "        # reference margin NO grad for the main loss\n",
    "        with torch.no_grad():\n",
    "            ch_ref, rj_ref = self._pair_scores_ids(self.ref_model, inputs, need_grad=False)\n",
    "            ch_ref, rj_ref = ch_ref.to(dev), rj_ref.to(dev)\n",
    "        \n",
    "        # δ selection\n",
    "        idx    = inputs[\"idx\"].to(dev).long()\n",
    "        idx_ch = (2 * idx).to(dev)\n",
    "        idx_rj = (2 * idx + 1).to(dev)\n",
    "\n",
    "        # Ensure delta params are on correct device\n",
    "        self.delta_raw = self.delta_raw.to(dev)\n",
    "        delta_vec = (self.delta_cap * torch.tanh(self.delta_raw)).to(dev)\n",
    "\n",
    "        delta_chosen   = delta_vec.index_select(0, idx_ch)\n",
    "        delta_rejected = delta_vec.index_select(0, idx_rj)\n",
    "        \n",
    "        # DPO + δ\n",
    "        margin   = (ch - ch_ref) - (rj - rj_ref) + (delta_chosen - delta_rejected)\n",
    "        dpo_loss = -F.logsigmoid(self.beta * margin).mean()\n",
    "        \n",
    "        # Null penalty depends ONLY on δ\n",
    "        null_pen = self._AT_delta(inputs, delta_chosen, delta_rejected)\n",
    "        \n",
    "        # Anti-collapse (optional)\n",
    "        amp_pen = -(delta_chosen.pow(2).mean() + delta_rejected.pow(2).mean()) * 0.5\n",
    "        \n",
    "        loss = dpo_loss + self.lambda_null * null_pen + self.lambda_amp * amp_pen\n",
    "\n",
    "        if return_outputs:\n",
    "            logs = {\n",
    "                \"aux/dpo\": dpo_loss.detach(),\n",
    "                \"aux/null\": (self.lambda_null * null_pen).detach(),\n",
    "                \"aux/amp\": (self.lambda_amp * amp_pen).detach(),\n",
    "                \"aux/delta_mean_abs\": torch.cat([delta_chosen, delta_rejected]).abs().mean().detach(),\n",
    "                \"aux/delta_max_abs\": torch.cat([delta_chosen, delta_rejected]).abs().max().detach(),\n",
    "            }\n",
    "            # --- δ grad debug ---\n",
    "            if self.delta_raw.grad is not None:\n",
    "                logs[\"aux/delta_grad_norm\"] = float(self.delta_raw.grad.detach().norm().cpu())\n",
    "            else:\n",
    "                logs[\"aux/delta_grad_norm\"] = 0.0\n",
    "            return loss, logs\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        model.train()\n",
    "        loss = self.compute_loss(model, inputs)\n",
    "        self.accelerator.backward(loss)\n",
    "\n",
    "        step_idx = self.state.global_step + 1\n",
    "        do_log = (step_idx % self.args.logging_steps == 0)\n",
    "        do_step = (step_idx % self.args.gradient_accumulation_steps == 0) or (self.args.gradient_accumulation_steps == 1)\n",
    "\n",
    "        if do_step and do_log:\n",
    "            self.log({\"grad_norm\": self._grad_norm(model)})\n",
    "\n",
    "        return loss.detach() / self.args.gradient_accumulation_steps\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _maybe_eval_and_log(self, global_step):\n",
    "        if self.args.eval_strategy == \"steps\" and (global_step % self.args.eval_steps == 0):\n",
    "            self.model.eval()\n",
    "            metrics = self.evaluate()\n",
    "            self.model.train()\n",
    "            if metrics:\n",
    "                # mirror Trainer.log\n",
    "                self.log(metrics)\n",
    "\n",
    "    def manual_train(self):\n",
    "        \"\"\"\n",
    "        Minimal, NCCL-safe manual loop:\n",
    "          - uses self.compute_loss (current model needs grad, ref is no-grad except inside _AT_delta),\n",
    "          - supports gradient accumulation, grad clipping, LR scheduler,\n",
    "          - optional eval/logging on steps.\n",
    "        Call this instead of Trainer.train().\n",
    "        \"\"\"\n",
    "        accelerator = self.accelerator\n",
    "        model = self.model\n",
    "        args = self.args\n",
    "    \n",
    "        # dataloader / optimizer / scheduler\n",
    "        train_loader = self.get_train_dataloader()\n",
    "        if self.optimizer is None:\n",
    "            self.create_optimizer()\n",
    "        if self.lr_scheduler is None:\n",
    "            # same schedule HF would build\n",
    "            num_update_steps_per_epoch = math.ceil(len(train_loader) / args.gradient_accumulation_steps)\n",
    "            max_steps = args.max_steps if args.max_steps > 0 else num_update_steps_per_epoch * args.num_train_epochs\n",
    "            self.create_scheduler(num_training_steps=max_steps)\n",
    "    \n",
    "        optimizer = self.optimizer\n",
    "        scheduler = self.lr_scheduler\n",
    "    \n",
    "        # put models in proper modes\n",
    "        model.train()\n",
    "        if self.ref_model is not None:\n",
    "            self.ref_model.eval()   # we never optimize ref\n",
    "    \n",
    "        # writers (main process only)\n",
    "        train_writer = _JsonlWriter(os.path.join(args.output_dir, \"train_metrics.jsonl\")) \\\n",
    "                       if accelerator.is_main_process else None\n",
    "        eval_writer  = _JsonlWriter(os.path.join(args.output_dir, \"eval_metrics.jsonl\")) \\\n",
    "                       if accelerator.is_main_process else None\n",
    "    \n",
    "        # state counters\n",
    "        global_step = 0\n",
    "        completed_steps = 0\n",
    "        num_update_steps_per_epoch = math.ceil(len(train_loader) / args.gradient_accumulation_steps)\n",
    "        total_train_steps = args.max_steps if args.max_steps > 0 else int(args.num_train_epochs * num_update_steps_per_epoch)\n",
    "    \n",
    "        # progress bar\n",
    "        pbar = tqdm(\n",
    "            total=total_train_steps,\n",
    "            disable=not accelerator.is_local_main_process,\n",
    "            desc=\"Manual training\"\n",
    "        )\n",
    "    \n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for epoch in range(int(args.num_train_epochs)):\n",
    "            # IMPORTANT: do not re-create sampler here; HuggingFace handles DDP sampler reseed internally.\n",
    "            for step, inputs in enumerate(train_loader):\n",
    "                # move to device like Trainer does\n",
    "                inputs = self._prepare_inputs(inputs)\n",
    "    \n",
    "                # gradient accumulation context\n",
    "                with accelerator.accumulate(model):\n",
    "                    # compute loss (our compute_loss can return (loss, logs) if return_outputs=True)\n",
    "                    out = self.compute_loss(model, inputs, return_outputs=True)\n",
    "                    if isinstance(out, tuple):\n",
    "                        loss, logs = out\n",
    "                    else:\n",
    "                        loss, logs = out, {}\n",
    "    \n",
    "                    # scale by accumulation (Trainer does this in return)\n",
    "                    loss_to_backprop = loss / args.gradient_accumulation_steps\n",
    "    \n",
    "                    accelerator.backward(loss_to_backprop)\n",
    "    \n",
    "                    # collect δ grad AFTER backward\n",
    "                    delta_gn = 0.0\n",
    "                    try:\n",
    "                        if getattr(self, \"delta_raw\", None) is not None and self.delta_raw.grad is not None:\n",
    "                            delta_gn = float(self.delta_raw.grad.detach().norm().item())\n",
    "                    except Exception:\n",
    "                        pass\n",
    "    \n",
    "                    # step only when gradients are synced across processes\n",
    "                    if accelerator.sync_gradients:\n",
    "                        if args.max_grad_norm is not None and args.max_grad_norm > 0:\n",
    "                            accelerator.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                        optimizer.zero_grad(set_to_none=True)\n",
    "                        completed_steps += 1\n",
    "                        global_step += 1\n",
    "                        pbar.update(1)\n",
    "    \n",
    "                        # ---- TRAIN LOGGING ----\n",
    "                        if (args.logging_strategy == \"steps\") and (global_step % args.logging_steps == 0):\n",
    "                            log_dict = {\n",
    "                                \"step\": global_step,\n",
    "                                \"epoch\": epoch + (step + 1) / max(1, len(train_loader)),\n",
    "                                \"lr\": scheduler.get_last_lr()[0] if scheduler is not None else None,\n",
    "                                \"loss\": float(loss.detach().cpu()),\n",
    "                                \"time\": time.time(),\n",
    "                                **{k: (float(v) if not isinstance(v, (int, float)) else float(v)) for k, v in logs.items()},\n",
    "                                \"aux/delta_grad_norm\": delta_gn,\n",
    "                            }\n",
    "                            # to HF Trainer history (and TB/W&B if enabled)\n",
    "                            self.log({k: v for k, v in log_dict.items() if k not in (\"time\",)})\n",
    "                            # to JSONL\n",
    "                            if train_writer: train_writer.write(log_dict)\n",
    "                            # console\n",
    "                            if accelerator.is_main_process:\n",
    "                                pbar.write(f\"[train] {_fmt_logs({k:v for k,v in log_dict.items() if k!='time'})}\")\n",
    "                                pbar.refresh()\n",
    "                            # persist trainer state snapshot\n",
    "                            try:\n",
    "                                self.state.save_to_json(os.path.join(args.output_dir, \"trainer_state.json\"))\n",
    "                            except Exception:\n",
    "                                pass\n",
    "    \n",
    "                        # ---- EVALUATION ----\n",
    "                        if self.args.eval_strategy == \"steps\" and (global_step % self.args.eval_steps == 0):\n",
    "                            # per-example rows go here if you want them:\n",
    "                            eval_rows_path = os.path.join(args.output_dir, f\"eval_step{global_step}.jsonl\")\n",
    "                            metrics = self.manual_evaluate(save_jsonl=eval_rows_path)\n",
    "                            if metrics:\n",
    "                                self.log(metrics)  # to HF history\n",
    "                                if eval_writer:\n",
    "                                    eval_writer.write({\"step\": global_step, \"time\": time.time(), **metrics})\n",
    "    \n",
    "                        if args.max_steps > 0 and global_step >= args.max_steps:\n",
    "                            break\n",
    "                    # end if sync_gradients\n",
    "    \n",
    "                    running_loss += loss.detach().float().item()\n",
    "    \n",
    "                # end accumulate\n",
    "    \n",
    "            if args.max_steps > 0 and global_step >= args.max_steps:\n",
    "                break\n",
    "    \n",
    "        pbar.close()\n",
    "    \n",
    "        # final eval if strategy=\"epoch\"\n",
    "        if args.eval_strategy == \"epoch\":\n",
    "            metrics = self.manual_evaluate(save_jsonl=os.path.join(args.output_dir, \"eval_final.jsonl\"))\n",
    "            if metrics:\n",
    "                self.log(metrics)\n",
    "                if eval_writer:\n",
    "                    eval_writer.write({\"step\": global_step, \"time\": time.time(), **metrics})\n",
    "    \n",
    "        # close writers\n",
    "        if train_writer: train_writer.close()\n",
    "        if eval_writer:  eval_writer.close()\n",
    "    \n",
    "        # mimic Trainer return value minimalism\n",
    "        return {\"global_step\": global_step, \"train_loss\": running_loss / max(1, global_step)}\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def manual_evaluate(self, eval_dataset=None, max_batches=None, save_jsonl=None):\n",
    "        \"\"\"\n",
    "        Pure inference eval:\n",
    "          - Computes response-only log-probs for model and ref\n",
    "          - margin = (ch - ch_ref) - (rj - rj_ref)\n",
    "          - acc = sigmoid(margin) > 0.5\n",
    "          - Uses accelerator.gather_for_metrics to aggregate across processes\n",
    "        Never builds a graph, never touches ref_model grads.\n",
    "        \"\"\"\n",
    "        self._ensure_ref_on_device()\n",
    "        model        = self.model\n",
    "        ref          = self.ref_model\n",
    "        accelerator  = self.accelerator\n",
    "        dev          = accelerator.device\n",
    "    \n",
    "        model.eval()\n",
    "        ref.eval()\n",
    "    \n",
    "        ds = eval_dataset if eval_dataset is not None else self.eval_dataset\n",
    "        if ds is None:\n",
    "            return {}\n",
    "    \n",
    "        dl = self.get_eval_dataloader(ds)\n",
    "    \n",
    "        all_acc     = []\n",
    "        all_margin  = []\n",
    "        all_ch      = []\n",
    "        all_rj      = []\n",
    "        all_ch_ref  = []\n",
    "        all_rj_ref  = []\n",
    "    \n",
    "        # optional writer\n",
    "        writer = None\n",
    "        if save_jsonl and accelerator.is_main_process:\n",
    "            import json, os\n",
    "            os.makedirs(os.path.dirname(save_jsonl) or \".\", exist_ok=True)\n",
    "            writer = open(save_jsonl, \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "        pbar = tqdm(\n",
    "            disable=not accelerator.is_local_main_process,\n",
    "            total=len(dl),\n",
    "            desc=\"Eval\"\n",
    "        )\n",
    "    \n",
    "        for step, batch in enumerate(dl):\n",
    "            if max_batches is not None and step >= max_batches:\n",
    "                break\n",
    "    \n",
    "            # move to device the same way Trainer does\n",
    "            batch = self._prepare_inputs(batch)\n",
    "    \n",
    "            # response-only scores (no grad)\n",
    "            ch_m, rj_m = self._pair_scores_ids(model, batch, need_grad=False)   # [B], [B]\n",
    "            ch_r, rj_r = self._pair_scores_ids(ref,   batch, need_grad=False)   # [B], [B]\n",
    "    \n",
    "            # ---- CRITICAL: force everything to the same device ----\n",
    "            ch_m  = ch_m.to(dev)\n",
    "            rj_m  = rj_m.to(dev)\n",
    "            ch_r  = ch_r.to(dev)\n",
    "            rj_r  = rj_r.to(dev)\n",
    "    \n",
    "            # margin & accuracy\n",
    "            margin = (ch_m - ch_r) - (rj_m - rj_r)                # [B]\n",
    "            acc    = (torch.sigmoid(margin) > 0.50).to(torch.float32)  # [B]\n",
    "    \n",
    "            # gather across processes safely\n",
    "            g_acc    = accelerator.gather_for_metrics(acc)\n",
    "            g_margin = accelerator.gather_for_metrics(margin)\n",
    "            g_ch     = accelerator.gather_for_metrics(ch_m)\n",
    "            g_rj     = accelerator.gather_for_metrics(rj_m)\n",
    "            g_chref  = accelerator.gather_for_metrics(ch_r)\n",
    "            g_rjref  = accelerator.gather_for_metrics(rj_r)\n",
    "    \n",
    "            all_acc.append(g_acc.cpu())\n",
    "            all_margin.append(g_margin.cpu())\n",
    "            all_ch.append(g_ch.cpu())\n",
    "            all_rj.append(g_rj.cpu())\n",
    "            all_ch_ref.append(g_chref.cpu())\n",
    "            all_rj_ref.append(g_rjref.cpu())\n",
    "    \n",
    "            # optional per-example dumps (only on main process)\n",
    "            if writer is not None and accelerator.is_main_process:\n",
    "                import json\n",
    "                for i in range(g_acc.numel()):\n",
    "                    row = {\n",
    "                        \"acc\":         float(g_acc[i].item()),\n",
    "                        \"margin\":      float(g_margin[i].item()),\n",
    "                        \"chosen\":      float(g_ch[i].item()),\n",
    "                        \"reject\":      float(g_rj[i].item()),\n",
    "                        \"chosen_ref\":  float(g_chref[i].item()),\n",
    "                        \"reject_ref\":  float(g_rjref[i].item()),\n",
    "                    }\n",
    "                    writer.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "    \n",
    "            pbar.update(1)\n",
    "    \n",
    "        pbar.close()\n",
    "        if writer is not None:\n",
    "            writer.close()\n",
    "    \n",
    "        # concat and compute metrics\n",
    "        if not all_acc:\n",
    "            return {}\n",
    "    \n",
    "        acc     = torch.cat(all_acc)\n",
    "        margin  = torch.cat(all_margin)\n",
    "        ch      = torch.cat(all_ch)\n",
    "        rj      = torch.cat(all_rj)\n",
    "        ch_ref  = torch.cat(all_ch_ref)\n",
    "        rj_ref  = torch.cat(all_rj_ref)\n",
    "    \n",
    "        metrics = {\n",
    "            \"eval/accuracy\":         float(acc.mean().item()),\n",
    "            \"eval/margin_mean\":      float(margin.mean().item()),\n",
    "            \"eval/margin_std\":       float(margin.std(unbiased=False).item()),\n",
    "            \"eval/chosen_mean\":      float(ch.mean().item()),\n",
    "            \"eval/reject_mean\":      float(rj.mean().item()),\n",
    "            \"eval/chosen_ref_mean\":  float(ch_ref.mean().item()),\n",
    "            \"eval/reject_ref_mean\":  float(rj_ref.mean().item()),\n",
    "        }\n",
    "    \n",
    "        # mirror Trainer behavior\n",
    "        if accelerator.is_main_process:\n",
    "            self.log(metrics)\n",
    "            msg = \" | \".join(f\"{k}={v:.6f}\" for k, v in metrics.items())\n",
    "            print(f\"[eval] {msg}\")\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "\n",
    "    # Override HF's evaluate to call our safe path\n",
    "    def evaluate(self, eval_dataset=None, **kwargs):\n",
    "        save_jsonl = kwargs.pop(\"save_jsonl\", None)\n",
    "        max_batches = kwargs.pop(\"max_batches\", None)\n",
    "        return self.manual_evaluate(eval_dataset=eval_dataset, max_batches=max_batches, save_jsonl=save_jsonl)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200e91f-4425-4d63-a2cf-a7f7b1868967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl.trainer.dpo_trainer import DataCollatorForPreference\n",
    "import torch\n",
    "\n",
    "class AuxDataCollatorForPreference(DataCollatorForPreference):\n",
    "    def torch_call(self, examples):\n",
    "        batch = super().torch_call(examples)\n",
    "        if \"idx\" in examples[0]:\n",
    "            batch[\"idx\"] = torch.tensor([ex[\"idx\"] for ex in examples], dtype=torch.long)\n",
    "        return batch\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    use_fast=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "collator = AuxDataCollatorForPreference(pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9709b21-3f06-489f-be70-8fdb11039863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import numpy as np\n",
    "\n",
    "def attach_idx_column(ds: Dataset) -> Dataset:\n",
    "    # 0..N-1, contiguous, stable across shuffles\n",
    "    return ds.map(lambda _, idx: {\"idx\": idx}, with_indices=True, batched=False)\n",
    "\n",
    "# --- params ---\n",
    "N = 10000\n",
    "SEED = 2025\n",
    "\n",
    "# raw_train = load_dataset(\"json\", data_files = \"hhrlhf_train.jsonl\")[\"train\"].select(range(10000))\n",
    "# raw_eval = load_dataset(\"json\", data_files = \"hhrlhf_test.jsonl\")[\"train\"].select(range(5000))\n",
    "\n",
    "# Load whole file, then downsample to N\n",
    "raw_ds = load_dataset(\"json\", data_files=\"mmlu_pro_prefs/test_pref_single.jsonl\")[\"train\"]\n",
    "#raw_train = ds_all.shuffle(seed=SEED).select(range(min(N, ds_all.num_rows)))\n",
    "#raw_eval = load_dataset(\"json\", data_files=\"mmlu_pro_prefs/test_pref_single.jsonl\")[\"train\"]\n",
    "\n",
    "#.select(range(min(N, ds_all.num_rows)))\n",
    "# train_ds = attach_idx_column(raw_train)\n",
    "# eval_ds = attach_idx_column(raw_eval)\n",
    "# Add idx\n",
    "split = raw_ds.train_test_split(test_size=0.2, seed=SEED)\n",
    "train_ds = attach_idx_column(split[\"train\"])\n",
    "eval_ds  = attach_idx_column(split[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02206c-0b23-46e7-8c0f-f25a877eefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from peft import PeftModel\n",
    "import torch, os\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    device_map=\"auto\",     # optional: auto place on GPU(s)\n",
    "    dtype=\"auto\",     # or torch.float16 / bfloat16\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "# Identify total layers\n",
    "layers = model.model.layers\n",
    "num_layers = len(layers)\n",
    "half = 0\n",
    "\n",
    "print(f\"Freezing first {half} layers out of {num_layers}\")\n",
    "\n",
    "# Freeze first half\n",
    "for layer in layers[:half]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb47405-792b-4d35-8335-95cc9eb6d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lora_target_modules(model, target_layer_ids, module_suffixes=[\"v_proj\", \"o_proj\", \"k_proj\", \"q_proj\"]):\n",
    "#         \"\"\"\n",
    "#         Extracts target module names for LoRA injection from selected GPT2 transformer layers.\n",
    "#         \"\"\"\n",
    "#         targets = set()\n",
    "#         for name, _ in model.named_modules():\n",
    "#             for layer_id in target_layer_ids:\n",
    "#                 if f\"layers.{layer_id}.\" in name and any(name.endswith(suffix) for suffix in module_suffixes):\n",
    "#                     targets.add(name)\n",
    "#         return list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726f742-e1ab-42cf-8dc6-fc0ff8e563d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# layers_to_include = [15]\n",
    "# target_modules = get_lora_target_modules(model, layers_to_include)\n",
    "        \n",
    "# lora_config = LoraConfig(\n",
    "#                 r=4,\n",
    "#                 lora_alpha=8,\n",
    "#                 lora_dropout=0.1,\n",
    "#                 target_modules=target_modules,\n",
    "#                 bias=\"none\",\n",
    "#                 )       \n",
    "\n",
    "# print(\"Applying LoRA adapters to the main model...\")\n",
    "# peft_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2349f-c0e5-4f20-a7b1-2fa9c88647f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "aux_args = DPOConfig(\n",
    "    output_dir=\"./llama1_hhrlhf/\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[],\n",
    "    fp16=False, \n",
    "    bf16=True,\n",
    "    padding_value=128001\n",
    ",\n",
    "    seed = 42,\n",
    ")\n",
    "\n",
    "aux_trainer = AuxDPOTrainer(   # ← the class we built earlier\n",
    "    model=model,\n",
    "    ref_model=None,                 # will freeze a copy automatically\n",
    "    args=aux_args,\n",
    "    train_dataset=train_ds,  # helpful train (with idx)\n",
    "    eval_dataset=eval_ds,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=collator,\n",
    "    # AuxDPO knobs\n",
    "    lambda_null=0.0001,      # weight on ||A^T δ||^2\n",
    "    lambda_amp=1,      # small negative L2 on δ_batch (anti-collapse)\n",
    "    delta_cap=1.0,        # |δ| bound via tanh\n",
    "    aux_lr=5e-3,          # LR for δ parameter\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6909de-db42-4c85-bf1b-0cfcbcd09588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = DPOTrainer(   # ← the class we built earlier\n",
    "#     model=model,\n",
    "#     ref_model=None,                 # will freeze a copy automatically\n",
    "#     args=aux_args,\n",
    "#     train_dataset=train_ds,  # helpful train (with idx)\n",
    "#     eval_dataset=eval_ds,\n",
    "#     processing_class=tokenizer,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9c2ea-b909-41db-aaeb-94169505f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_trainer.manual_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e214ecb-26ba-416b-8018-fc8665465dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f65280-92f1-4e87-ba56-16ce1d8e8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in aux_trainer.state.log_history:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76c7d6-6f64-4c7a-a4d6-30a5c154a5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
