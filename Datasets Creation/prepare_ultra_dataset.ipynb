{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c25c397-fdfc-44ef-b29f-f52006984cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37985b85f0314100b770cb7e1845e62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff982669552c4f1eb9623afcb9e79dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00003-e82ff6ed69653c(…):   0%|          | 0.00/70.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df32e409dd4461da3f263a46314a8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00003-0196dad938ced3(…):   0%|          | 0.00/67.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bb98a780e44abb99c75766d10d9744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00003-33462d35a35bd4(…):   0%|          | 0.00/111M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c68791c4464c9ab14e98a663dead1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/340025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcc4bffc64548ecaae0ad5fe0c31a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt/chosen/rejected:   0%|          | 0/340025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef917a46ca7418b9400ef07704b6d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/340025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795afd4c9ba349a9b7f3874f5e331abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropping empty rows:   0%|          | 0/340025 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cdd70fa09046b4b8911db439aa4150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/340 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 339477 rows to ultra_pref_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "# make_ultra_pref_jsonl.py\n",
    "from datasets import load_dataset, Features, Value\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "Msg = Dict[str, Any]\n",
    "Conv = Union[List[Msg], Dict[str, Any], str]\n",
    "\n",
    "def _as_messages(x: Conv) -> List[Msg]:\n",
    "    \"\"\"Coerce a conversation object into a list of {role, content} messages.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, dict):\n",
    "        # common pattern: {\"messages\": [...]}\n",
    "        if \"messages\" in x and isinstance(x[\"messages\"], list):\n",
    "            return x[\"messages\"]\n",
    "        # fallback: treat dict as a single message if it looks like one\n",
    "        if \"role\" in x and \"content\" in x:\n",
    "            return [x]\n",
    "    if isinstance(x, str):\n",
    "        # sometimes serialized JSON as string\n",
    "        try:\n",
    "            obj = json.loads(x)\n",
    "            return _as_messages(obj)\n",
    "        except Exception:\n",
    "            # if it's just a bare string, treat as a single user message\n",
    "            return [{\"role\": \"user\", \"content\": x}]\n",
    "    # last resort\n",
    "    return []\n",
    "\n",
    "def _content_to_text(c: Any) -> str:\n",
    "    \"\"\"Extract text from a message 'content' which might be str or list of segments.\"\"\"\n",
    "    if c is None:\n",
    "        return \"\"\n",
    "    if isinstance(c, str):\n",
    "        return c\n",
    "    if isinstance(c, list):\n",
    "        # e.g., [{\"type\":\"text\",\"text\":\"...\"}, {\"type\":\"...\"}] or list[str]\n",
    "        parts = []\n",
    "        for seg in c:\n",
    "            if isinstance(seg, str):\n",
    "                parts.append(seg)\n",
    "            elif isinstance(seg, dict):\n",
    "                # prefer typical keys\n",
    "                for k in (\"text\", \"content\", \"value\"):\n",
    "                    if isinstance(seg.get(k), str):\n",
    "                        parts.append(seg[k])\n",
    "                        break\n",
    "        return \"\\n\".join(parts)\n",
    "    if isinstance(c, dict):\n",
    "        # some providers put the text under \"text\" or \"content\"\n",
    "        for k in (\"text\", \"content\", \"value\"):\n",
    "            if isinstance(c.get(k), str):\n",
    "                return c[k]\n",
    "        return json.dumps(c, ensure_ascii=False)\n",
    "    return str(c)\n",
    "\n",
    "def extract_prompt_and_response(conv: Conv) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    From a chat transcript, return:\n",
    "      prompt  = concatenation of user messages\n",
    "      reply   = last assistant message (if multiple, join them)\n",
    "    \"\"\"\n",
    "    msgs = _as_messages(conv)\n",
    "    user_chunks, assistant_chunks = [], []\n",
    "    for m in msgs:\n",
    "        role = (m.get(\"role\") or \"\").lower().strip()\n",
    "        txt = _content_to_text(m.get(\"content\"))\n",
    "        if not txt:\n",
    "            continue\n",
    "        if role == \"user\":\n",
    "            user_chunks.append(txt)\n",
    "        elif role == \"assistant\":\n",
    "            assistant_chunks.append(txt)\n",
    "        # ignore system/tool/etc. for this export\n",
    "\n",
    "    prompt = \"\\n\\n\".join(user_chunks).strip()\n",
    "    if not assistant_chunks:\n",
    "        reply = \"\"  # guard; dataset should have it, but stay safe\n",
    "    else:\n",
    "        # prefer the last assistant message as the response\n",
    "        reply = assistant_chunks[-1].strip()\n",
    "    return prompt, reply\n",
    "\n",
    "def row_to_pref(example: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Each example has keys 'chosen' and 'rejected' that are chat transcripts.\n",
    "    We build: prompt (from user messages), chosen/rejected (assistant replies).\n",
    "    \"\"\"\n",
    "    chosen_conv = example.get(\"chosen\", {})\n",
    "    rejected_conv = example.get(\"rejected\", {})\n",
    "\n",
    "    prompt_c, chosen = extract_prompt_and_response(chosen_conv)\n",
    "    prompt_r, rejected = extract_prompt_and_response(rejected_conv)\n",
    "\n",
    "    # Prefer chosen's prompt; if empty, fall back to rejected's\n",
    "    prompt = prompt_c if prompt_c else prompt_r\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt or \"\",\n",
    "        \"chosen\": chosen or \"\",\n",
    "        \"rejected\": rejected or \"\",\n",
    "    }\n",
    "\n",
    "def make_jsonl(split: str = \"train\", out_path: str = \"ultra_pref.jsonl\"):\n",
    "    ds = load_dataset(\"RLHFlow/UltraFeedback-preference-standard\", split=split)\n",
    "    cleaned = ds.map(\n",
    "        row_to_pref,\n",
    "        remove_columns=[c for c in ds.column_names if c not in (\"chosen\", \"rejected\")],\n",
    "        desc=\"Extracting prompt/chosen/rejected\"\n",
    "    )\n",
    "\n",
    "    # Enforce string schema & drop empties\n",
    "    cleaned = cleaned.cast(Features({\"prompt\": Value(\"string\"),\n",
    "                                     \"chosen\": Value(\"string\"),\n",
    "                                     \"rejected\": Value(\"string\")}))\n",
    "    cleaned = cleaned.filter(lambda ex: bool(ex[\"prompt\"]) and bool(ex[\"chosen\"]) and bool(ex[\"rejected\"]),\n",
    "                             desc=\"Dropping empty rows\")\n",
    "\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    cleaned.to_json(out_path)\n",
    "    print(f\"Wrote {len(cleaned)} rows to {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # change split or path if you want dev/test variants too\n",
    "    make_jsonl(split=\"train\", out_path=\"ultra_pref_train.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea53494-ac88-47b4-9bc1-f0c1e1980e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int main() {\\n    string country;\\n    // prompt user for input\\n    cout << \"Enter the name of a country: \";\\n    cin >> country;\\n    // check if country borders the Mediterranean Sea\\n    if (endsWith(country, \"Mediterranean\")) {\\n        cout << \"Yes, the country \" << country\\n             << \" borders the Mediterranean Sea.\";\\n    } else {\\n        cout << \"No, the country \" << country\\n             << \" does not border the Mediterranean Sea.\";\\n    }\\n    return 0;\\n}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"ultra_pref_train.jsonl\", lines=True)\n",
    "df.iloc[0].to_dict()['rejected']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b75350-c366-40d8-925e-8b47d4634287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
